{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmb0vvacBCgM",
        "outputId": "d6107271-5877-4738-9f69-c7955d2d3216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction completed.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load ResNet18 pre-trained model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define feature extraction function\n",
        "def extract_features(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "    return features\n",
        "\n",
        "# Extract features for all images in a folder\n",
        "image_folder = \"/content/drive/MyDrive/cropped\"\n",
        "features = []\n",
        "for img in os.listdir(image_folder):\n",
        "    # Check if the item is a file before processing\n",
        "    image_path = os.path.join(image_folder, img)\n",
        "    if os.path.isfile(image_path):  # Only process files, skip directories\n",
        "        features.append(extract_features(image_path))\n",
        "\n",
        "print(\"Feature extraction completed.\") # Optional: Print a message to indicate completion"
      ]
    },
    {
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.cluster import BisectingKMeans\n",
        "from sklearn.metrics import fowlkes_mallows_score, silhouette_score\n",
        "\n",
        "# Set the root directory for the dataset\n",
        "dataset_dir = \"/content/drive/MyDrive/cropped\"  # Update this to your directory path\n",
        "\n",
        "# Step 1: Feature Extraction\n",
        "# Load ResNet18 pre-trained model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define feature extraction function\n",
        "def extract_features(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "    return features.flatten().numpy()\n",
        "\n",
        "# Extract features and collect ground truth labels\n",
        "features = []\n",
        "labels = []\n",
        "class_names = os.listdir(dataset_dir)  # Get subdirectory names (classes)\n",
        "for label, class_name in enumerate(class_names):\n",
        "    class_dir = os.path.join(dataset_dir, class_name)\n",
        "    for image_name in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_name)\n",
        "        features.append(extract_features(image_path))\n",
        "        labels.append(label)  # Assign numerical labels for each class\n",
        "\n",
        "# Step 2: Dimensionality Reduction\n",
        "# Perform PCA to reduce dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "reduced_features = pca.fit_transform(features)\n",
        "\n",
        "# Step 3: Clustering Methods\n",
        "# K-means clustering\n",
        "kmeans_random = KMeans(n_clusters=4, init='random', random_state=42).fit(reduced_features)\n",
        "kmeans_plus = KMeans(n_clusters=4, init='k-means++', random_state=42).fit(reduced_features)\n",
        "\n",
        "# Bisecting K-means\n",
        "bisect_kmeans = BisectingKMeans(n_clusters=4, random_state=42).fit(reduced_features)\n",
        "\n",
        "# Spectral clustering\n",
        "spectral = SpectralClustering(n_clusters=4, random_state=42, affinity='nearest_neighbors').fit(reduced_features)\n",
        "\n",
        "# DBSCAN\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5).fit(reduced_features)\n",
        "\n",
        "# Agglomerative clustering\n",
        "agg_single = AgglomerativeClustering(n_clusters=4, linkage='single').fit(reduced_features)\n",
        "agg_complete = AgglomerativeClustering(n_clusters=4, linkage='complete').fit(reduced_features)\n",
        "agg_average = AgglomerativeClustering(n_clusters=4, linkage='average').fit(reduced_features)\n",
        "agg_ward = AgglomerativeClustering(n_clusters=4, linkage='ward').fit(reduced_features)\n",
        "\n",
        "# Step 4: Clustering Evaluation\n",
        "# Evaluate each clustering method\n",
        "methods = {\n",
        "    \"KMeans Random\": kmeans_random.labels_,\n",
        "    \"KMeans Plus\": kmeans_plus.labels_,\n",
        "    \"Bisecting KMeans\": bisect_kmeans.labels_,\n",
        "    \"Spectral\": spectral.labels_,\n",
        "    \"DBSCAN\": dbscan.labels_,\n",
        "    \"Agglomerative Single\": agg_single.labels_,\n",
        "    \"Agglomerative Complete\": agg_complete.labels_,\n",
        "    \"Agglomerative Average\": agg_average.labels_,\n",
        "    \"Agglomerative Ward\": agg_ward.labels_,\n",
        "}\n",
        "\n",
        "\n",
        "evaluation_results = {}\n",
        "for method, predicted_labels in methods.items():\n",
        "    fmi = fowlkes_mallows_score(labels, predicted_labels)\n",
        "    # Check if predicted labels have more than one unique label\n",
        "    if len(np.unique(predicted_labels)) > 1:\n",
        "        silhouette = silhouette_score(reduced_features, predicted_labels)\n",
        "    else:\n",
        "        silhouette = -1  # Assign a default value for single-cluster cases\n",
        "    evaluation_results[method] = {\"FMI\": fmi, \"Silhouette\": silhouette}\n",
        "\n",
        "\n",
        "# Rank methods by FMI and Silhouette\n",
        "ranked_by_fmi = sorted(evaluation_results.items(), key=lambda x: x[1][\"FMI\"], reverse=True)\n",
        "ranked_by_silhouette = sorted(evaluation_results.items(), key=lambda x: x[1][\"Silhouette\"], reverse=True)\n",
        "\n",
        "# Display rankings\n",
        "print(\"Ranking by Fowlkes-Mallows Index:\")\n",
        "for rank, (method, scores) in enumerate(ranked_by_fmi, start=1):\n",
        "    print(f\"{rank}. {method}: FMI={scores['FMI']}\")\n",
        "\n",
        "print(\"\\nRanking by Silhouette Coefficient:\")\n",
        "for rank, (method, scores) in enumerate(ranked_by_silhouette, start=1):\n",
        "    print(f\"{rank}. {method}: Silhouette={scores['Silhouette']}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MalR2JU3Ebpl",
        "outputId": "43d0a130-3914-452b-a9e4-c4fa7b8c5738"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking by Fowlkes-Mallows Index:\n",
            "1. Spectral: FMI=0.9399393480851093\n",
            "2. Bisecting KMeans: FMI=0.9399341044331888\n",
            "3. Agglomerative Average: FMI=0.9366335483807186\n",
            "4. KMeans Random: FMI=0.9353106596092164\n",
            "5. KMeans Plus: FMI=0.9353106596092164\n",
            "6. Agglomerative Complete: FMI=0.9324979746800472\n",
            "7. Agglomerative Ward: FMI=0.9280427868785972\n",
            "8. DBSCAN: FMI=0.5003361862284268\n",
            "9. Agglomerative Single: FMI=0.49833288338614196\n",
            "\n",
            "Ranking by Silhouette Coefficient:\n",
            "1. KMeans Random: Silhouette=0.6111951248315856\n",
            "2. KMeans Plus: Silhouette=0.6111951248315856\n",
            "3. Spectral: Silhouette=0.6110473945624377\n",
            "4. Bisecting KMeans: Silhouette=0.610433589299064\n",
            "5. Agglomerative Ward: Silhouette=0.6100224128753775\n",
            "6. Agglomerative Complete: Silhouette=0.6059990465423257\n",
            "7. Agglomerative Average: Silhouette=0.6059027589412035\n",
            "8. Agglomerative Single: Silhouette=-0.1994733995415742\n",
            "9. DBSCAN: Silhouette=-1\n"
          ]
        }
      ]
    }
  ]
}